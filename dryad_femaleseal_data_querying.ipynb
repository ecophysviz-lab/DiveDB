{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Querying and Exporting\n",
    "\n",
    "This notebook demonstrates the process of querying data from Delta Lake and visualizing it in various formats.  It is particularly set up for the Dryad dataset, but the process for accessing other datasets is the same.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restimates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_Days</th>\n",
       "      <th>Days_Elapsed</th>\n",
       "      <th>daily_recording</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Lon360</th>\n",
       "      <th>daily_diving</th>\n",
       "      <th>daily_SI</th>\n",
       "      <th>daily_long_SI</th>\n",
       "      <th>daily_filtered_long_drift</th>\n",
       "      <th>...</th>\n",
       "      <th>TOPPID</th>\n",
       "      <th>SEALID</th>\n",
       "      <th>Percent_of_Trip</th>\n",
       "      <th>dailydive_glide</th>\n",
       "      <th>dailydive_long_glide</th>\n",
       "      <th>dailydive_KAMI</th>\n",
       "      <th>daily_all_sleep</th>\n",
       "      <th>daily_all_REM</th>\n",
       "      <th>dailydive_sleep</th>\n",
       "      <th>dailydive_REM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>732000</td>\n",
       "      <td>0</td>\n",
       "      <td>14.240000</td>\n",
       "      <td>37.223897</td>\n",
       "      <td>-122.513835</td>\n",
       "      <td>237.486165</td>\n",
       "      <td>12.264444</td>\n",
       "      <td>1.751111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124444</td>\n",
       "      <td>...</td>\n",
       "      <td>2004001</td>\n",
       "      <td>R881</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732001</td>\n",
       "      <td>1</td>\n",
       "      <td>23.975556</td>\n",
       "      <td>37.616749</td>\n",
       "      <td>-123.104691</td>\n",
       "      <td>236.895309</td>\n",
       "      <td>21.828889</td>\n",
       "      <td>1.731111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>2004001</td>\n",
       "      <td>R881</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>732002</td>\n",
       "      <td>2</td>\n",
       "      <td>23.895556</td>\n",
       "      <td>37.956043</td>\n",
       "      <td>-123.254476</td>\n",
       "      <td>236.745524</td>\n",
       "      <td>21.957778</td>\n",
       "      <td>1.426667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.113333</td>\n",
       "      <td>...</td>\n",
       "      <td>2004001</td>\n",
       "      <td>R881</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>732003</td>\n",
       "      <td>3</td>\n",
       "      <td>23.988889</td>\n",
       "      <td>38.643718</td>\n",
       "      <td>-123.548055</td>\n",
       "      <td>236.451945</td>\n",
       "      <td>22.002222</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804444</td>\n",
       "      <td>...</td>\n",
       "      <td>2004001</td>\n",
       "      <td>R881</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>732004</td>\n",
       "      <td>4</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>39.051504</td>\n",
       "      <td>-124.127636</td>\n",
       "      <td>235.872364</td>\n",
       "      <td>21.728889</td>\n",
       "      <td>1.813333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997778</td>\n",
       "      <td>...</td>\n",
       "      <td>2004001</td>\n",
       "      <td>R881</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>732017</td>\n",
       "      <td>17</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>44.202867</td>\n",
       "      <td>-133.267593</td>\n",
       "      <td>226.732407</td>\n",
       "      <td>21.180000</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.731111</td>\n",
       "      <td>...</td>\n",
       "      <td>2004005</td>\n",
       "      <td>O176</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>732018</td>\n",
       "      <td>18</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>44.616750</td>\n",
       "      <td>-133.809109</td>\n",
       "      <td>226.190891</td>\n",
       "      <td>21.831111</td>\n",
       "      <td>1.675556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.806667</td>\n",
       "      <td>...</td>\n",
       "      <td>2004005</td>\n",
       "      <td>O176</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>732019</td>\n",
       "      <td>19</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>45.013053</td>\n",
       "      <td>-134.148557</td>\n",
       "      <td>225.851443</td>\n",
       "      <td>21.708889</td>\n",
       "      <td>1.840000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231111</td>\n",
       "      <td>...</td>\n",
       "      <td>2004005</td>\n",
       "      <td>O176</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>732020</td>\n",
       "      <td>20</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>45.464614</td>\n",
       "      <td>-134.044286</td>\n",
       "      <td>225.955714</td>\n",
       "      <td>21.560000</td>\n",
       "      <td>1.975556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.775556</td>\n",
       "      <td>...</td>\n",
       "      <td>2004005</td>\n",
       "      <td>O176</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>732021</td>\n",
       "      <td>21</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>45.959338</td>\n",
       "      <td>-134.138104</td>\n",
       "      <td>225.861896</td>\n",
       "      <td>21.186667</td>\n",
       "      <td>2.337778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>2004005</td>\n",
       "      <td>O176</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_Days  Days_Elapsed  daily_recording        Lat        Long  \\\n",
       "0         732000             0        14.240000  37.223897 -122.513835   \n",
       "1         732001             1        23.975556  37.616749 -123.104691   \n",
       "2         732002             2        23.895556  37.956043 -123.254476   \n",
       "3         732003             3        23.988889  38.643718 -123.548055   \n",
       "4         732004             4        24.000000  39.051504 -124.127636   \n",
       "..           ...           ...              ...        ...         ...   \n",
       "195       732017            17        24.000000  44.202867 -133.267593   \n",
       "196       732018            18        24.000000  44.616750 -133.809109   \n",
       "197       732019            19        24.000000  45.013053 -134.148557   \n",
       "198       732020            20        24.000000  45.464614 -134.044286   \n",
       "199       732021            21        24.000000  45.959338 -134.138104   \n",
       "\n",
       "         Lon360  daily_diving  daily_SI  daily_long_SI  \\\n",
       "0    237.486165     12.264444  1.751111            0.0   \n",
       "1    236.895309     21.828889  1.731111            0.0   \n",
       "2    236.745524     21.957778  1.426667            0.0   \n",
       "3    236.451945     22.002222  1.540000            0.0   \n",
       "4    235.872364     21.728889  1.813333            0.0   \n",
       "..          ...           ...       ...            ...   \n",
       "195  226.732407     21.180000  2.444444            0.0   \n",
       "196  226.190891     21.831111  1.675556            0.0   \n",
       "197  225.851443     21.708889  1.840000            0.0   \n",
       "198  225.955714     21.560000  1.975556            0.0   \n",
       "199  225.861896     21.186667  2.337778            0.0   \n",
       "\n",
       "     daily_filtered_long_drift  ...   TOPPID  SEALID  Percent_of_Trip  \\\n",
       "0                     0.124444  ...  2004001    R881                0   \n",
       "1                     4.800000  ...  2004001    R881                1   \n",
       "2                     2.113333  ...  2004001    R881                3   \n",
       "3                     0.804444  ...  2004001    R881                4   \n",
       "4                     0.997778  ...  2004001    R881                5   \n",
       "..                         ...  ...      ...     ...              ...   \n",
       "195                   0.731111  ...  2004005    O176               21   \n",
       "196                   1.806667  ...  2004005    O176               22   \n",
       "197                   0.231111  ...  2004005    O176               24   \n",
       "198                   0.775556  ...  2004005    O176               25   \n",
       "199                   0.600000  ...  2004005    O176               26   \n",
       "\n",
       "     dailydive_glide  dailydive_long_glide  dailydive_KAMI  daily_all_sleep  \\\n",
       "0                NaN                   NaN             NaN              NaN   \n",
       "1                NaN                   NaN             NaN              NaN   \n",
       "2                NaN                   NaN             NaN              NaN   \n",
       "3                NaN                   NaN             NaN              NaN   \n",
       "4                NaN                   NaN             NaN              NaN   \n",
       "..               ...                   ...             ...              ...   \n",
       "195              NaN                   NaN             NaN              NaN   \n",
       "196              NaN                   NaN             NaN              NaN   \n",
       "197              NaN                   NaN             NaN              NaN   \n",
       "198              NaN                   NaN             NaN              NaN   \n",
       "199              NaN                   NaN             NaN              NaN   \n",
       "\n",
       "     daily_all_REM  dailydive_sleep  dailydive_REM  \n",
       "0              NaN              NaN            NaN  \n",
       "1              NaN              NaN            NaN  \n",
       "2              NaN              NaN            NaN  \n",
       "3              NaN              NaN            NaN  \n",
       "4              NaN              NaN            NaN  \n",
       "..             ...              ...            ...  \n",
       "195            NaN              NaN            NaN  \n",
       "196            NaN              NaN            NaN  \n",
       "197            NaN              NaN            NaN  \n",
       "198            NaN              NaN            NaN  \n",
       "199            NaN              NaN            NaN  \n",
       "\n",
       "[200 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "restimates = pd.read_csv(\"/app/data/files/11_Restimates_ALL_DailyActivity.csv\")\n",
    "\n",
    "def matlab_datenum_to_datetime_vectorized(\n",
    "    matlab_serial_dates: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts a vector of MATLAB datenum values to pandas datetime in a vectorized manner.\n",
    "\n",
    "    MATLAB datenum starts from year 0000-01-00, while Python's datetime starts from 1970-01-01.\n",
    "    We need to adjust by subtracting the number of days between these dates.\n",
    "    \"\"\"\n",
    "    # MATLAB serialized dates start from 0000-01-01\n",
    "    matlab_start_date = np.datetime64(\"0000-01-01\")\n",
    "\n",
    "    # Split into days and fractional days\n",
    "    days = np.floor(matlab_serial_dates).astype(int)\n",
    "    fraction = matlab_serial_dates - days\n",
    "\n",
    "    # Convert MATLAB serial date to Python datetime\n",
    "    converted_dates = (\n",
    "        matlab_start_date\n",
    "        + days.astype(\"timedelta64[D]\")\n",
    "        + (fraction * 24 * 3600).astype(\"timedelta64[s]\")\n",
    "    ).astype(\"datetime64[ns]\")\n",
    "    return converted_dates\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sample = restimates.head(200)\n",
    "display(sample)\n",
    "\n",
    "# display(restimates[restimates[\"Deployment_ID\"] == 2004001])\n",
    "# # restimates[restimates[\"Deployment_ID\"] == 2004001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal_ID</th>\n",
       "      <th>Deployment_ID</th>\n",
       "      <th>Tags_SatTag_Manufacturer</th>\n",
       "      <th>Tags_SatTag_Model</th>\n",
       "      <th>Tags_SatTag_ID</th>\n",
       "      <th>Tags_PTT</th>\n",
       "      <th>Data_Track_QCFlag</th>\n",
       "      <th>Tags_SatTag_Comments</th>\n",
       "      <th>Tags_TDR1_Manufacturer</th>\n",
       "      <th>Tags_TDR1_Model</th>\n",
       "      <th>...</th>\n",
       "      <th>Deployment_Trip</th>\n",
       "      <th>Animal_BirthYear</th>\n",
       "      <th>Animal_AgeClass</th>\n",
       "      <th>Animal_Sex</th>\n",
       "      <th>Deployment_Manipulation</th>\n",
       "      <th>Deployment_ManipulationType</th>\n",
       "      <th>Animal_HadPup</th>\n",
       "      <th>Deployment_Year</th>\n",
       "      <th>is2017</th>\n",
       "      <th>max_QC_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>6018</td>\n",
       "      <td>2017001</td>\n",
       "      <td>Wildlife Computers</td>\n",
       "      <td>SPOT5</td>\n",
       "      <td>13s1533</td>\n",
       "      <td>139053.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wildlife Computers</td>\n",
       "      <td>Mk9</td>\n",
       "      <td>...</td>\n",
       "      <td>PB</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Animal_ID  Deployment_ID Tags_SatTag_Manufacturer Tags_SatTag_Model  \\\n",
       "558      6018        2017001       Wildlife Computers             SPOT5   \n",
       "\n",
       "    Tags_SatTag_ID  Tags_PTT  Data_Track_QCFlag Tags_SatTag_Comments  \\\n",
       "558        13s1533  139053.0                  3                  NaN   \n",
       "\n",
       "    Tags_TDR1_Manufacturer Tags_TDR1_Model  ... Deployment_Trip  \\\n",
       "558     Wildlife Computers             Mk9  ...              PB   \n",
       "\n",
       "    Animal_BirthYear  Animal_AgeClass Animal_Sex Deployment_Manipulation  \\\n",
       "558           2011.0            Adult          F                       N   \n",
       "\n",
       "    Deployment_ManipulationType Animal_HadPup Deployment_Year  is2017  \\\n",
       "558                         NaN           NaN          2017.0    True   \n",
       "\n",
       "    max_QC_flag  \n",
       "558           3  \n",
       "\n",
       "[1 rows x 50 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"/app/data/files/NES_TrackingDiving_MetaData.csv\")\n",
    "metadata[\n",
    "    ['Animal_ID', 'Deployment_ID', 'Deployment_Trip']\n",
    "]\n",
    "\n",
    "metadata['is2017'] = metadata['Deployment_ID'].apply(lambda x: str(x).startswith('2017'))\n",
    "metadata['max_QC_flag'] = metadata[['Data_Track_QCFlag', 'Data_TDR1_QCFlag']].max(axis=1)\n",
    "metadata = metadata[metadata['max_QC_flag'] <= 3]\n",
    "# metadata = metadata[metadata['is2017']]\n",
    "metadata[metadata['Deployment_ID'] == 2017001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_Days</th>\n",
       "      <th>Days_Elapsed</th>\n",
       "      <th>daily_recording</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Lon360</th>\n",
       "      <th>daily_diving</th>\n",
       "      <th>daily_SI</th>\n",
       "      <th>daily_long_SI</th>\n",
       "      <th>daily_filtered_long_drift</th>\n",
       "      <th>...</th>\n",
       "      <th>TOPPID</th>\n",
       "      <th>SEALID</th>\n",
       "      <th>Percent_of_Trip</th>\n",
       "      <th>dailydive_glide</th>\n",
       "      <th>dailydive_long_glide</th>\n",
       "      <th>dailydive_KAMI</th>\n",
       "      <th>daily_all_sleep</th>\n",
       "      <th>daily_all_REM</th>\n",
       "      <th>dailydive_sleep</th>\n",
       "      <th>dailydive_REM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>732000</td>\n",
       "      <td>0</td>\n",
       "      <td>14.240000</td>\n",
       "      <td>37.223897</td>\n",
       "      <td>-122.513835</td>\n",
       "      <td>237.486165</td>\n",
       "      <td>12.264444</td>\n",
       "      <td>1.751111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124444</td>\n",
       "      <td>...</td>\n",
       "      <td>2004001</td>\n",
       "      <td>R881</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732001</td>\n",
       "      <td>1</td>\n",
       "      <td>23.975556</td>\n",
       "      <td>37.616749</td>\n",
       "      <td>-123.104691</td>\n",
       "      <td>236.895309</td>\n",
       "      <td>21.828889</td>\n",
       "      <td>1.731111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>2004001</td>\n",
       "      <td>R881</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>732002</td>\n",
       "      <td>2</td>\n",
       "      <td>23.895556</td>\n",
       "      <td>37.956043</td>\n",
       "      <td>-123.254476</td>\n",
       "      <td>236.745524</td>\n",
       "      <td>21.957778</td>\n",
       "      <td>1.426667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.113333</td>\n",
       "      <td>...</td>\n",
       "      <td>2004001</td>\n",
       "      <td>R881</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>732003</td>\n",
       "      <td>3</td>\n",
       "      <td>23.988889</td>\n",
       "      <td>38.643718</td>\n",
       "      <td>-123.548055</td>\n",
       "      <td>236.451945</td>\n",
       "      <td>22.002222</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804444</td>\n",
       "      <td>...</td>\n",
       "      <td>2004001</td>\n",
       "      <td>R881</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>732004</td>\n",
       "      <td>4</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>39.051504</td>\n",
       "      <td>-124.127636</td>\n",
       "      <td>235.872364</td>\n",
       "      <td>21.728889</td>\n",
       "      <td>1.813333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997778</td>\n",
       "      <td>...</td>\n",
       "      <td>2004001</td>\n",
       "      <td>R881</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52739</th>\n",
       "      <td>738174</td>\n",
       "      <td>213</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>37.520102</td>\n",
       "      <td>-125.131445</td>\n",
       "      <td>234.868555</td>\n",
       "      <td>22.451111</td>\n",
       "      <td>1.288889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.593333</td>\n",
       "      <td>...</td>\n",
       "      <td>2020024</td>\n",
       "      <td>6609</td>\n",
       "      <td>98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52740</th>\n",
       "      <td>738175</td>\n",
       "      <td>214</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>37.133202</td>\n",
       "      <td>-124.512049</td>\n",
       "      <td>235.487951</td>\n",
       "      <td>22.402222</td>\n",
       "      <td>1.328889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.797778</td>\n",
       "      <td>...</td>\n",
       "      <td>2020024</td>\n",
       "      <td>6609</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52741</th>\n",
       "      <td>738176</td>\n",
       "      <td>215</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>36.749071</td>\n",
       "      <td>-123.653268</td>\n",
       "      <td>236.346732</td>\n",
       "      <td>21.744444</td>\n",
       "      <td>1.995556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.366667</td>\n",
       "      <td>...</td>\n",
       "      <td>2020024</td>\n",
       "      <td>6609</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52742</th>\n",
       "      <td>738177</td>\n",
       "      <td>216</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>36.693417</td>\n",
       "      <td>-122.907452</td>\n",
       "      <td>237.092548</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>1.548889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>2020024</td>\n",
       "      <td>6609</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52743</th>\n",
       "      <td>738178</td>\n",
       "      <td>217</td>\n",
       "      <td>11.833333</td>\n",
       "      <td>36.973782</td>\n",
       "      <td>-122.271540</td>\n",
       "      <td>237.728460</td>\n",
       "      <td>10.442222</td>\n",
       "      <td>1.173333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.624444</td>\n",
       "      <td>...</td>\n",
       "      <td>2020024</td>\n",
       "      <td>6609</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46760 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_Days  Days_Elapsed  daily_recording        Lat        Long  \\\n",
       "0           732000             0        14.240000  37.223897 -122.513835   \n",
       "1           732001             1        23.975556  37.616749 -123.104691   \n",
       "2           732002             2        23.895556  37.956043 -123.254476   \n",
       "3           732003             3        23.988889  38.643718 -123.548055   \n",
       "4           732004             4        24.000000  39.051504 -124.127636   \n",
       "...            ...           ...              ...        ...         ...   \n",
       "52739       738174           213        24.000000  37.520102 -125.131445   \n",
       "52740       738175           214        24.000000  37.133202 -124.512049   \n",
       "52741       738176           215        24.000000  36.749071 -123.653268   \n",
       "52742       738177           216        24.000000  36.693417 -122.907452   \n",
       "52743       738178           217        11.833333  36.973782 -122.271540   \n",
       "\n",
       "           Lon360  daily_diving  daily_SI  daily_long_SI  \\\n",
       "0      237.486165     12.264444  1.751111            0.0   \n",
       "1      236.895309     21.828889  1.731111            0.0   \n",
       "2      236.745524     21.957778  1.426667            0.0   \n",
       "3      236.451945     22.002222  1.540000            0.0   \n",
       "4      235.872364     21.728889  1.813333            0.0   \n",
       "...           ...           ...       ...            ...   \n",
       "52739  234.868555     22.451111  1.288889            0.0   \n",
       "52740  235.487951     22.402222  1.328889            0.0   \n",
       "52741  236.346732     21.744444  1.995556            0.0   \n",
       "52742  237.092548     22.200000  1.548889            0.0   \n",
       "52743  237.728460     10.442222  1.173333            0.0   \n",
       "\n",
       "       daily_filtered_long_drift  ...   TOPPID  SEALID  Percent_of_Trip  \\\n",
       "0                       0.124444  ...  2004001    R881                0   \n",
       "1                       4.800000  ...  2004001    R881                1   \n",
       "2                       2.113333  ...  2004001    R881                3   \n",
       "3                       0.804444  ...  2004001    R881                4   \n",
       "4                       0.997778  ...  2004001    R881                5   \n",
       "...                          ...  ...      ...     ...              ...   \n",
       "52739                   2.593333  ...  2020024    6609               98   \n",
       "52740                   1.797778  ...  2020024    6609               99   \n",
       "52741                   3.366667  ...  2020024    6609               99   \n",
       "52742                   3.200000  ...  2020024    6609              100   \n",
       "52743                   1.624444  ...  2020024    6609              100   \n",
       "\n",
       "       dailydive_glide  dailydive_long_glide  dailydive_KAMI  daily_all_sleep  \\\n",
       "0                  NaN                   NaN             NaN              NaN   \n",
       "1                  NaN                   NaN             NaN              NaN   \n",
       "2                  NaN                   NaN             NaN              NaN   \n",
       "3                  NaN                   NaN             NaN              NaN   \n",
       "4                  NaN                   NaN             NaN              NaN   \n",
       "...                ...                   ...             ...              ...   \n",
       "52739              NaN                   NaN             NaN              NaN   \n",
       "52740              NaN                   NaN             NaN              NaN   \n",
       "52741              NaN                   NaN             NaN              NaN   \n",
       "52742              NaN                   NaN             NaN              NaN   \n",
       "52743              NaN                   NaN             NaN              NaN   \n",
       "\n",
       "       daily_all_REM  dailydive_sleep  dailydive_REM  \n",
       "0                NaN              NaN            NaN  \n",
       "1                NaN              NaN            NaN  \n",
       "2                NaN              NaN            NaN  \n",
       "3                NaN              NaN            NaN  \n",
       "4                NaN              NaN            NaN  \n",
       "...              ...              ...            ...  \n",
       "52739            NaN              NaN            NaN  \n",
       "52740            NaN              NaN            NaN  \n",
       "52741            NaN              NaN            NaN  \n",
       "52742            NaN              NaN            NaN  \n",
       "52743            NaN              NaN            NaN  \n",
       "\n",
       "[46760 rows x 37 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restimates_quality = restimates[restimates['TOPPID'].isin(metadata['Deployment_ID'])]\n",
    "restimates_quality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`daily_filtered_long_drift_long_SI`: sum of time spent sleeping\n",
    "\n",
    "`daily_filtered_long_drift`: sum of time spent sleeping underwater\n",
    "\n",
    "`daily_long_SI`: sum of time spent sleeping at surface in hours\n",
    "\n",
    "`Lon360`: longitude in 360\n",
    "\n",
    "`Lat`: latitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "def get_mask(gdf, buffer_size=0.1):\n",
    "    gdf_poly = gdf.geometry.apply(lambda x: x.buffer(buffer_size))\n",
    "    dissolved_poly = unary_union(gdf_poly.geometry)\n",
    "    dissolved_gdf = gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"id\": [0]}),\n",
    "        geometry=[dissolved_poly],\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    return dissolved_gdf\n",
    "\n",
    "\n",
    "def create_line_gdf(gdf, description=\"Sick Seal 2017001\"):\n",
    "    points = list(gdf.geometry.apply(lambda pt: (pt.x, pt.y)))\n",
    "    return gpd.GeoDataFrame(\n",
    "        pd.DataFrame({\"id\": [0], \"description\": [description]}),\n",
    "        geometry=[LineString(points)],\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    \n",
    "\n",
    "def plot_restimates(df, buffer_size=0.7, highlight_id=2017001):\n",
    "    df = df.reset_index()\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df,\n",
    "        geometry=gpd.points_from_xy(\n",
    "            df[\"Lon360\"], \n",
    "            df[\"Lat\"],\n",
    "        ),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    \n",
    "    dissolved_gdf = get_mask(gdf, buffer_size)\n",
    "    ax = dissolved_gdf.plot(alpha=0.5)\n",
    "    gdf[gdf['TOPPID'] == highlight_id].plot(markersize=0.1, ax=ax, legend=True, color='black')\n",
    "    \n",
    "    specimen = gdf[gdf['TOPPID'] == highlight_id]\n",
    "    line_gdf = create_line_gdf(specimen)\n",
    "    line_gdf.plot(ax=ax, legend=True, color='black')\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def explore_restimates(df, buffer_size=0.7, highlight_id=2017001):\n",
    "    \n",
    "    import folium\n",
    "    df = df.reset_index()\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df,\n",
    "        geometry=gpd.points_from_xy(\n",
    "            df[\"Lon360\"], \n",
    "            df[\"Lat\"],\n",
    "        ),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    dissolved_gdf = get_mask(gdf, buffer_size)\n",
    "    \n",
    "    specimen = gdf[gdf['TOPPID'] == highlight_id]\n",
    "    line_gdf = create_line_gdf(specimen)\n",
    "    \n",
    "    m = folium.Map(location=[0, 0], zoom_start=2)\n",
    "\n",
    "    # Add the first GeoDataFrame\n",
    "    folium.GeoJson(\n",
    "        dissolved_gdf,\n",
    "        name='Base Distribution',\n",
    "        style_function=lambda x: {\n",
    "            'fillColor': 'blue',\n",
    "            'fillOpacity': 0.5\n",
    "        },\n",
    "    ).add_to(m)\n",
    "    \n",
    "    folium.GeoJson(\n",
    "        gdf,\n",
    "        name='Base Distribution',\n",
    "        style_function=lambda x: {\n",
    "            'fillColor': 'blue',\n",
    "            'fillOpacity': 0.5,\n",
    "            'alpha': 0.5\n",
    "        },\n",
    "    ).add_to(m)\n",
    "\n",
    "    # # Add the second GeoDataFrame\n",
    "    folium.GeoJson(\n",
    "        line_gdf,\n",
    "        name='2017001',\n",
    "        style_function=lambda x: {\n",
    "            'fillColor': 'black',\n",
    "            'color': 'black',\n",
    "            'weight': 0.5,\n",
    "            'fillOpacity': 0.5\n",
    "        },\n",
    "        tooltip=folium.GeoJsonTooltip(fields=['description'])\n",
    "    ).add_to(m)\n",
    "    \n",
    "    folium.TileLayer(\n",
    "        tiles=ctx.providers.Esri.WorldImagery,\n",
    "        name='Satellite',\n",
    "        attr=ctx.providers.Esri.WorldImagery['attribution']\n",
    "    ).add_to(m)\n",
    "\n",
    "    # # Add layer control to toggle layers\n",
    "    # folium.LayerControl().add_to(m)\n",
    "    \n",
    "    return m\n",
    "\n",
    "    \n",
    "explore_restimates(restimates_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import DiveDB.services.duck_pond\n",
    "importlib.reload(DiveDB.services.duck_pond)\n",
    "\n",
    "from DiveDB.services.duck_pond import DuckPond\n",
    "import pandas as pd\n",
    "\n",
    "duckpond = DuckPond()\n",
    "\n",
    "df = duckpond.conn.sql(    \n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        deployment, \n",
    "        datetime,\n",
    "        date_trunc('day', datetime) as day, \n",
    "        value.float as value,\n",
    "        label\n",
    "    FROM DataLake \n",
    "    WHERE \n",
    "        label IN ('lat', 'lon', 'corr_depth')\n",
    "    \"\"\"\n",
    ").df()\n",
    "\n",
    "df2 = pd.merge(\n",
    "    pd.merge(\n",
    "        df[df['label'] == 'lat'].rename(columns={'minval': 'min_lat', 'maxval': 'max_lat'}).drop(columns=[\"label\", \"day\"]),\n",
    "        df[df['label'] == 'lon'].rename(columns={'minval': 'min_lon', 'maxval': 'max_lon'}).drop(columns=[\"label\", \"day\"]),\n",
    "        on=['deployment', 'datetime'],\n",
    "        suffixes=('_lat', '_lon')\n",
    "    ),\n",
    "    df[df['label'] == 'corr_depth'].rename(columns={'minval': 'min_depth', 'maxval': 'max_depth'}).drop(columns=[\"label\"]),\n",
    "    on=['animal', 'day'],\n",
    "    suffixes=('', '_depth')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df2.reset_index(),\n",
    "    geometry=gpd.points_from_xy(df2.reset_index().min_lon, df2.reset_index().min_lat),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "gdf = gdf[gdf.min_lon < -120]\n",
    "\n",
    "ax = gdf.plot(column=\"animal\", figsize=(15, 15), legend=True, alpha=0.7)\n",
    "ctx.add_basemap(ax, crs=gdf.crs.to_string(), source=ctx.providers.Esri.WorldImagery, attribution_size=3, zoom=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "FACTOR = 1\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df2.reset_index(),\n",
    "    geometry=gpd.points_from_xy(df2.reset_index().min_lon.apply(lambda x: math.floor(x * FACTOR) / FACTOR), df2.reset_index().min_lat.apply(lambda x: math.floor(x * FACTOR) / FACTOR)),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "gdf = gdf[gdf.min_lon < -120]\n",
    "\n",
    "\n",
    "display(gdf)\n",
    "\n",
    "gdf2 = gdf[[\"geometry\", \"max_depth\"]].groupby([\"geometry\"]).count().rename(columns={\"max_depth\": \"count\"}).sort_values(by=\"count\", ascending=False).reset_index()\n",
    "display(gdf2)\n",
    "\n",
    "gdf2.geometry = gdf2.geometry.apply(lambda pt: Polygon([(pt.x, pt.y), (pt.x+1/FACTOR, pt.y), (pt.x+1/FACTOR, pt.y+1/FACTOR), (pt.x, pt.y+1/FACTOR)]))\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    gdf2.reset_index(),\n",
    "    geometry=gdf2.geometry,\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "\n",
    "ax = gdf.plot(column=\"count\", cmap=\"YlOrRd\", figsize=(15, 15), legend=True, alpha=0.9)\n",
    "ctx.add_basemap(ax, crs=gdf.crs.to_string(), source=ctx.providers.Esri.WorldImagery, attribution_size=3, zoom=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "FACTOR = 1\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df2.reset_index(),\n",
    "    geometry=gpd.points_from_xy(df2.reset_index().min_lon.apply(lambda x: math.floor(x * FACTOR) / FACTOR), df2.reset_index().min_lat.apply(lambda x: math.floor(x * FACTOR) / FACTOR)),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "gdf = gdf[gdf.min_lon < -120]\n",
    "\n",
    "\n",
    "display(gdf)\n",
    "\n",
    "gdf2 = gdf[[\"animal\", \"geometry\"]].groupby([\"geometry\"]).agg({\"animal\": \"nunique\"}).rename(columns={\"animal\": \"count\"}).sort_values(by=\"count\", ascending=False).reset_index()\n",
    "\n",
    "display(gdf2)\n",
    "\n",
    "gdf2.geometry = gdf2.geometry.apply(lambda pt: Polygon([(pt.x, pt.y), (pt.x+1/FACTOR, pt.y), (pt.x+1/FACTOR, pt.y+1/FACTOR), (pt.x, pt.y+1/FACTOR)]))\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    gdf2.reset_index(),\n",
    "    geometry=gdf2.geometry,\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "\n",
    "ax = gdf.plot(column=\"count\", cmap=\"YlOrRd\", vmax=10, figsize=(15, 15), legend=True, alpha=0.9)\n",
    "ctx.add_basemap(ax, crs=gdf.crs.to_string(), source=ctx.providers.Esri.WorldImagery, attribution_size=3, zoom=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the DuckPond connection to query directly\n",
    "More complex queries can be run directly on the DuckPond connection. This is useful for queries that may not be supported by the `get_delta_data` method which has those involving grouping or aggregations. \n",
    "\n",
    "DuckDB runs sql very similar in syntax to other SQL databases. A full breakdown of the syntax can be found [in the documenation](https://duckdb.org/docs/sql/introduction).\n",
    "\n",
    "The connection object can be found in the `duckpond.conn` attribute. To run queries, use the `sql` method which also returns a [DuckDB DuckDBPyConnection](https://duckdb.org/docs/api/python/reference/#duckdb.DuckDBPyConnection) which can be used to convert the data in many different formats including the following ([see documentation for a full list](https://duckdb.org/docs/api/python/conversion#result-conversion-duckdb-results-to-python))\n",
    "- NumPy Array (`.fetchnumpy()`)\n",
    "- Pandas DataFrame (`.df()`)\n",
    "- Arrows Table (`.arrow()`)\n",
    "- Polars DataFrame (`.pl()`)\n",
    "\n",
    "##### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "# Reload the DuckPond module to pick up any changes\n",
    "import DiveDB.services.duck_pond\n",
    "importlib.reload(DiveDB.services.duck_pond)\n",
    "from DiveDB.services.duck_pond import DuckPond\n",
    "\n",
    "duckpond = DuckPond()\n",
    "\n",
    "df = duckpond.conn.sql(f\"\"\"\n",
    "SELECT label, avg(value) as mean_data\n",
    "FROM (\n",
    "    SELECT label, value.int as value\n",
    "    FROM DataLake\n",
    "    WHERE label = 'sensor_data_ecg'\n",
    "    OR label = 'sensor_data_light'\n",
    ")\n",
    "GROUP BY label\n",
    "\"\"\").df()\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining Queries\n",
    "Queries can be chained together to form a pipeline. This is useful for running complex queries that involve multiple steps.\n",
    "\n",
    "##### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "# Reload the DuckPond module to pick up any changes\n",
    "import DiveDB.services.duck_pond\n",
    "importlib.reload(DiveDB.services.duck_pond)\n",
    "from DiveDB.services.duck_pond import DuckPond\n",
    "\n",
    "duckpond = DuckPond()\n",
    "\n",
    "# Get the filtered data\n",
    "filtered_data = duckpond.get_delta_data(    \n",
    "    animal_ids=\"oror-002\",\n",
    "    frequency=10, # Resample values to 10 Hz and make sure each signal has the same time intervals\n",
    "    # Aggregation of events (think state events - behaviors) type: state (has state and end dates)\n",
    "    classes=\"sensor_data_accelerometer\",\n",
    "    \n",
    ")\n",
    "\n",
    "display(filtered_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Variables\n",
    "Sometimes we don't want to hardcode variables in our queries. We can use the `execute` method to pass variables to the query.\n",
    "\n",
    "##### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "# Reload the DuckPond module to pick up any changes\n",
    "import DiveDB.services.duck_pond\n",
    "importlib.reload(DiveDB.services.duck_pond)\n",
    "from DiveDB.services.duck_pond import DuckPond\n",
    "\n",
    "duckpond = DuckPond()\n",
    "\n",
    "label = \"sensor_data_temperature\"\n",
    "df = duckpond.conn.execute(f\"\"\"\n",
    "SELECT label, avg(value) as mean_data\n",
    "FROM (\n",
    "    SELECT label, value.float as value\n",
    "    FROM DataLake\n",
    "    WHERE label = $1\n",
    ")\n",
    "GROUP BY label\n",
    "\"\"\", [label]).df()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Metadata Database\n",
    "We can also query the Metadata Database directly. This is useful for querying data that is not stored in Delta Lake and joining it for queries on measurement data.\n",
    "\n",
    "##### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "# Reload the DuckPond module to pick up any changes\n",
    "import DiveDB.services.duck_pond\n",
    "importlib.reload(DiveDB.services.duck_pond)\n",
    "from DiveDB.services.duck_pond import DuckPond\n",
    "\n",
    "duckpond = DuckPond()\n",
    "\n",
    "\n",
    "# Show all tables we have access to\n",
    "print(duckpond.get_db_schema())\n",
    "\n",
    "df = duckpond.conn.sql(\"\"\"\n",
    "SELECT value.float as value\n",
    "FROM DataLake \n",
    "JOIN Metadata.public.Animals ON DataLake.animal = Animals.id\n",
    "WHERE Animals.project_id = 'test12_Wednesday'\n",
    "AND label = 'sensor_data_temperature'\n",
    "\"\"\").df()\n",
    "\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data to EDF\n",
    "When it's easier to work with EDF files, we can export the data to an EDF file. This is useful for working with the data in other software packages.\n",
    "\n",
    "The `create_mne_edf` function takes a DuckDB connection and a file path and creates an EDF file. \n",
    "\n",
    "*Note: it currently requires a lot of memory. Can be improved.*\n",
    "*Note: it's lacking support for most info fields in the EDF file. Can be improved.*\n",
    "\n",
    "##### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import DiveDB.services.duck_pond\n",
    "import DiveDB.services.utils.edf\n",
    "importlib.reload(DiveDB.services.duck_pond)\n",
    "importlib.reload(DiveDB.services.utils.edf)\n",
    "\n",
    "from DiveDB.services.duck_pond import DuckPond\n",
    "from DiveDB.services.utils.edf import create_mne_edf\n",
    "\n",
    "duckpond = DuckPond()\n",
    "\n",
    "conn = duckpond.get_delta_data(    \n",
    "    animal_ids=\"mian-003\",\n",
    "    labels=[\"ECG_ICA2\", \"EEG_ICA5\"],\n",
    "    limit=1000000,\n",
    ")\n",
    "\n",
    "create_mne_edf(conn, \"test.edf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data to MNE Signal Array\n",
    "For working with the data in MNE, we can export the data to an MNE Signal Array. This is useful for manipulating the data in MNE.\n",
    "\n",
    "The `create_mne_array` function takes a DuckDB connection and returns an MNE RawArray.\n",
    "\n",
    "##### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import DiveDB.services.duck_pond\n",
    "importlib.reload(DiveDB.services.duck_pond)\n",
    "from DiveDB.services.duck_pond import DuckPond\n",
    "from DiveDB.services.utils.edf import create_mne_array\n",
    "\n",
    "duckpond = DuckPond()\n",
    "\n",
    "conn = duckpond.get_delta_data(    \n",
    "    animal_ids=\"mian-003\",\n",
    "    labels=\"ECG_ICA2\",\n",
    "    limit=1000000,\n",
    ")\n",
    "\n",
    "raw = create_mne_array(conn, resample=100, l_freq=1, h_freq=20)\n",
    "display(raw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
