{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Uploader\n",
    "\n",
    "This notebook demonstrates the process of uploading EDF files data to a database and Delta Lake storage. \n",
    "It includes the setup and execution of the data upload process, as well as querying the uploaded data for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To upload data:\n",
    "The `edf_file_paths` list contains the paths to the EDF files that we want to upload. \n",
    "These files are located in the `../data/files/` directory and are named `test12_Wednesday_05_DAY1_PROCESSED.edf` and `test12_Wednesday_05_DAY2_PROCESSED.edf`.\n",
    "\n",
    "The `metadata_file_path` variable holds the path to the CSV file containing metadata for the EDF files. \n",
    "This file is also located in the `../data/files/` directory and is named `Sleep Study Metadata.csv`.\n",
    "The `metadata_map` dictionary is used to map the columns in the CSV metadata file to the corresponding mode. \n",
    "The keys in the dictionary represent the fields in the database, and the values represent the column names in the CSV file.\n",
    "For example:\n",
    "    - \"animal\" maps to the \"Nickname\" column in the CSV file.\n",
    "    - \"deployment\" maps to the \"Deployment\" column in the CSV file.\n",
    "    - \"logger\" maps to the \"Logger Used\" column in the CSV file.\n",
    "    - \"recording\" maps to the \"Recording ID\" column in the CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory does not exist: /data/delta-lake\n",
      "Uploading ../data/files/test12_Wednesday_05_DAY1_PROCESSED.edf to Swift\n",
      "Uploading ../data/files/test12_Wednesday_05_DAY2_PROCESSED.edf to Swift\n",
      "Processing 36 signals in 2 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing signals: 100%|██████████| 36/36 [11:42<00:00, 19.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "\n",
    "import shutil\n",
    "import importlib\n",
    "\n",
    "import services.data_uploader\n",
    "importlib.reload(services.data_uploader)\n",
    "from services.data_uploader import DataUploader\n",
    "\n",
    "data_uploader = DataUploader()\n",
    "\n",
    "edf_file_paths = [\n",
    "    \"../data/files/test12_Wednesday_05_DAY1_PROCESSED.edf\",\n",
    "    \"../data/files/test12_Wednesday_05_DAY2_PROCESSED.edf\"\n",
    "]\n",
    "\n",
    "metadata_file_path = \"../data/files/Sleep Study Metadata.csv\"\n",
    "\n",
    "metadata_map = {\n",
    "    \"animal\": \"Nickname\",\n",
    "    \"deployment\": \"Deployment\",\n",
    "    \"logger\": \"Logger Used\",\n",
    "    \"recording\": \"Recording ID\"\n",
    "}\n",
    "\n",
    "\n",
    "# Delete directory at os.environ[\"CONTAINER_DELTA_LAKE_PATH\"]\n",
    "delta_lake_path = os.environ.get(\"CONTAINER_DELTA_LAKE_PATH\")\n",
    "if delta_lake_path and os.path.exists(delta_lake_path):\n",
    "    shutil.rmtree(delta_lake_path)\n",
    "    print(f\"Deleted directory: {delta_lake_path}\")\n",
    "else:\n",
    "    print(f\"Directory does not exist: {delta_lake_path}\")\n",
    "\n",
    "\n",
    "\n",
    "data_uploader.upload_edf(edf_file_paths, metadata_file_path, metadata_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (86_400_500, 1)\n",
      "┌────────┐\n",
      "│ 'data' │\n",
      "│ ---    │\n",
      "│ str    │\n",
      "╞════════╡\n",
      "│ data   │\n",
      "│ data   │\n",
      "│ data   │\n",
      "│ data   │\n",
      "│ data   │\n",
      "│ …      │\n",
      "│ data   │\n",
      "│ data   │\n",
      "│ data   │\n",
      "│ data   │\n",
      "│ data   │\n",
      "└────────┘\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "import services.duck_pond\n",
    "import services.utils.edf\n",
    "importlib.reload(services.duck_pond)\n",
    "importlib.reload(services.utils.edf)\n",
    "\n",
    "from services.duck_pond import DuckPond\n",
    "from services.utils.edf import create_mne_array, create_mne_edf\n",
    "\n",
    "duckpond = DuckPond()\n",
    "\n",
    "df = duckpond.conn.sql(\"SELECT 'data' FROM DeltaLake where signal_name = 'ECG_ICA2'\")\n",
    "\n",
    "# df = duckpond.get_delta_data(\n",
    "#     signal_names=[\"ECG_ICA2\", \"EEG_ICA5\"],\n",
    "#     date_range=(\n",
    "#         \"2019-10-26 14:46:21.008\", \n",
    "#         \"2019-10-26 14:46:21.008\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "print(df.pl())\n",
    "# raw = create_mne_edf(df, \"/data/test.edf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (200_000, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>data</th></tr><tr><td>f64</td></tr></thead><tbody><tr><td>-142.663706</td></tr><tr><td>-142.663706</td></tr><tr><td>-142.663706</td></tr><tr><td>-142.663706</td></tr><tr><td>-142.663706</td></tr><tr><td>&hellip;</td></tr><tr><td>304.876341</td></tr><tr><td>116.786648</td></tr><tr><td>-112.890715</td></tr><tr><td>-423.380484</td></tr><tr><td>-636.044709</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (200_000, 1)\n",
       "┌─────────────┐\n",
       "│ data        │\n",
       "│ ---         │\n",
       "│ f64         │\n",
       "╞═════════════╡\n",
       "│ -142.663706 │\n",
       "│ -142.663706 │\n",
       "│ -142.663706 │\n",
       "│ -142.663706 │\n",
       "│ -142.663706 │\n",
       "│ …           │\n",
       "│ 304.876341  │\n",
       "│ 116.786648  │\n",
       "│ -112.890715 │\n",
       "│ -423.380484 │\n",
       "│ -636.044709 │\n",
       "└─────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled 9 bad heart rate values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "198.67549668874173"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyologger.process_data.feature_generation_utils import get_heart_rate\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT data\n",
    "FROM DeltaLake\n",
    "WHERE signal_name = 'ECG_ICA2'\n",
    "LIMIT 5000000;\n",
    "\"\"\"\n",
    "\n",
    "df = duckpond.conn.execute(query).pl()\n",
    "display(df)\n",
    "\n",
    "heart_rate = get_heart_rate(df[\"data\"])\n",
    "\n",
    "heart_rate.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
