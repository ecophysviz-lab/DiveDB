{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export EDF\n",
    "\n",
    "This notebook demonstrates the process of exporting DiveDB data as an EDF file.\n",
    "\n",
    "While under development, it also contains the prototype (non-library) code; that'll be deleted when this notebook is ready to be merged into the main branch.\n",
    "\n",
    "Punch list:\n",
    "- [x] Make a list\n",
    "- [x] Understand task :) \n",
    "- [ ] Prototype:\n",
    "    - [x] Load basic metadata\n",
    "    - [x] Load signals\n",
    "    - [x] Generate EDF file \n",
    "        - [X] Can mne serve our needs here? Check if multiple sample rates, arbitrary metadata: edfio can!\n",
    "        - [x] Decide if different library OR extend mne: use edfio, which is what mne depends on \n",
    "    - [ ] Test EDF file can be opened externally (e.g. through EDF.jl or other app)\n",
    "    - [ ] Add metadata to EDF header\n",
    "- [ ] In tests, write (failing) test for basic new functionality\n",
    "- [ ] Turn prototype into library code - test passes!\n",
    "- [ ] Write up edge case tests\n",
    "    - [ ] Make 'em pass OR file 'em\n",
    "- [ ] Clean up this notebook (delete this punch list!)\n",
    "- [ ] Mark PR ready for review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: this is the end goal\n",
    "\n",
    "```python\n",
    "# Example of usage once complete\n",
    "\n",
    "from DiveDB.services.duck_pond import DuckPond\n",
    "\n",
    "duckpond = DuckPond(os.environ[\"CONTAINER_DELTA_LAKE_PATH\"])\n",
    "\n",
    "dive_data = duckpond.get_delta_data(    \n",
    "    labels=[\"eeg\"],\n",
    "    animal_ids=\"apfo-001a\",\n",
    ")\n",
    "\n",
    "dive_data.export_to_edf(\"path_to_output.edf\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get metadata\n",
    "import os\n",
    "import importlib\n",
    "import DiveDB.services.duck_pond as dp\n",
    "importlib.reload(dp)\n",
    "\n",
    "duckpond = dp.DuckPond(os.environ[\"CONTAINER_DELTA_LAKE_PATH\"])\n",
    "\n",
    "# Example from the querying_docs notebook\n",
    "data = duckpond.get_delta_data(    \n",
    "    labels=[\"derived_data_depth\"],\n",
    "    animal_ids=\"apfo-001a\",\n",
    "    frequency=1/60,  # Once a minute\n",
    ")\n",
    "display(data)\n",
    "\n",
    "# Okay, but is there a way to find out what animal_ids, etc, are available?\n",
    "# Time to go spelunking!\n",
    "duckpond.get_db_schema()\n",
    "\n",
    "# ...okay, cool. :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a sql query as well (also ripped from the querying_docs notebook)\n",
    "labels_df = duckpond.conn.sql(f\"\"\"\n",
    "    SELECT label\n",
    "    FROM (\n",
    "        SELECT DISTINCT label\n",
    "        FROM DataLake\n",
    "    )\n",
    "\"\"\").df()\n",
    "display(labels_df)\n",
    "\n",
    "animals_df = duckpond.conn.sql(f\"\"\"\n",
    "    SELECT animal\n",
    "    FROM (\n",
    "        SELECT DISTINCT animal\n",
    "        FROM DataLake\n",
    "    )\n",
    "\"\"\").df()\n",
    "display(animals_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df[\"label\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commenting out b/c otherwise this crashes my kernel (if i do other stuff after it)\n",
    "\n",
    "# # Once more from the other notebook....\n",
    "# # Get the filtered data\n",
    "# resampled_data = duckpond.get_delta_data(    \n",
    "#     animal_ids=\"apfo-001a\",\n",
    "#     # Resample values to 100 Hz and make sure each signal has the same time intervals\n",
    "#     frequency=100,\n",
    "#     # Aggregation of events (think state events - behaviors) type: state (has state and end dates)\n",
    "#     classes=\"sensor_data_accelerometer\",\n",
    "# )\n",
    "# display(resampled_data)\n",
    "# # Huh. okay, `frequency` triggering a materialization + resample is interesting, not sure \n",
    "# # I would have guessed that from the API! I would have guessed that had to do with \n",
    "# # the sampling rate of the recording.\n",
    "\n",
    "# # Okay, so the output of `get_delta_data` with a set frequency returns the signal as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Is there a way to get the original sample rate? \n",
    "unmaterialized_data = duckpond.get_delta_data(    \n",
    "    animal_ids=\"apfo-001a\",\n",
    "    # Resample values to 10 Hz and make sure each signal has the same time intervals\n",
    "    frequency=None,\n",
    "    # Aggregation of events (think state events - behaviors) type: state (has state and end dates)\n",
    "    classes=\"sensor_data_accelerometer\",\n",
    ")\n",
    "display(unmaterialized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... okay, got it. now, let's do what needs doing. \n",
    "# But also, keep in mind that we should NOT pass a frequency into `get_delta_data`\n",
    "# before EDF export unless we are very explicit about what we are doing and why. \n",
    "\n",
    "# When we don't pass in a frequency (i.e., resample), we get a DuckDBPyRelation\n",
    "# out of `get_delta_data`\n",
    "print(type(unmaterialized_data))\n",
    "\n",
    "# ...from task, I think we want a DuckDBPyConnection instead? Currently unclear to me\n",
    "# how these interop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, now to an EDF! \n",
    "# Let's do the demo from edfio (what mne depends on for its EDF support)\n",
    "\n",
    "from edfio import Edf, EdfSignal, read_edf\n",
    "import numpy as np\n",
    "\n",
    "# edfio's example\n",
    "example_edf = Edf(\n",
    "    [\n",
    "        EdfSignal(np.random.randn(30 * 256), sampling_frequency=256, label=\"EEG Fpz\"),\n",
    "        EdfSignal(np.random.randn(30), sampling_frequency=1, label=\"Body Temp\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "outpath = \".tmp/example.edf\"\n",
    "example_edf.write(outpath)\n",
    "\n",
    "example_edf_roundtrip = read_edf(outpath)\n",
    "display(example_edf_roundtrip.signals)\n",
    "display(example_edf_roundtrip.signals[0].data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...and now with our data!\n",
    "# Can we make an EDF from our data? \n",
    "# intentionally picking signals with different sampling rates\n",
    "\n",
    "# ...normally we could query these all at the same time, except that we're putting limits\n",
    "# on here so that we don't have to get ALL values for each signal. Also, in real case, \n",
    "# this is where we'd pull all data and then split it up and make one EDF file per animal/deployment/etc. \n",
    "# For now? Hard code it, bebe!\n",
    "signals = []\n",
    "for label in [\"ax\", \"derived_data_depth\"]:\n",
    "    df = duckpond.get_delta_data(    \n",
    "        animal_ids=\"apfo-001a\",\n",
    "        labels=[label],\n",
    "        limit=1000,\n",
    "    ).df()\n",
    "\n",
    "    # TODO-safety: check that there's only one value after the unique, check that \n",
    "    # this is an integer value or whatever the EDF spec requires, etc\n",
    "    sampling_rate = df[\"datetime\"].diff()[1:].dt.total_seconds().unique()[0]\n",
    "    sampling_frequency = int(1/sampling_rate) # TODO-safety: don't just blindly round o_O\n",
    "    \n",
    "    label_sanitized = label if len(label) <= 16 else label[0:16] # lol EDF\n",
    "\n",
    "    # TODO-correctly! need to figure out max signal length, then start time, then \n",
    "    # Lpad to the correct start time + lpad to the correct stop time (lol EDF)\n",
    "    # For now, we're faking it. We happen to know that the maximum duration signal \n",
    "    # of these two is 20 s, so lets zero-pad to that:\n",
    "    signal_data = np.zeros(20 * sampling_frequency)\n",
    "    signal_data[0:len(df[label].values)] = df[label].values # There has to be a pandas (where is nrow?) way to do this\n",
    "\n",
    "    signal = EdfSignal(signal_data,\n",
    "                       sampling_frequency=sampling_frequency, \n",
    "                       label=label_sanitized)\n",
    "    signals.append(signal)\n",
    "    \n",
    "divedb_edf = Edf(signals)\n",
    "path = \".tmp/prototype.edf\"\n",
    "divedb_edf.write(path)\n",
    "\n",
    "divedb_edf_roundtrip = read_edf(path)\n",
    "display(divedb_edf_roundtrip.signals)\n",
    "display(divedb_edf_roundtrip.signals[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huzzah! Time to clean up :) \n",
    "# ...actually false. Time to figure out how to get the metadata into the EDF header!\n",
    "# Check the edfio API: https://github.com/the-siesta-group/edfio?tab=readme-ov-file#usage \n",
    "# and https://edfio.readthedocs.io/en/stable/examples.html "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
