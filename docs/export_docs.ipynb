{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export EDF\n",
    "\n",
    "This notebook demonstrates the process of exporting DiveDB data as an EDF file.\n",
    "\n",
    "While under development, it also contains the prototype (non-library) code; that'll be deleted when this notebook is ready to be merged into the main branch.\n",
    "\n",
    "Punch list:\n",
    "- [x] Make a list\n",
    "- [x] Understand task :) \n",
    "- [ ] Prototype:\n",
    "    - [x] Load basic metadata\n",
    "    - [x] Load signals\n",
    "    - [x] Generate EDF file \n",
    "        - [X] Can mne serve our needs here? Check if multiple sample rates, arbitrary metadata: edfio can!\n",
    "        - [x] Decide if different library OR extend mne: use edfio, which is what mne depends on \n",
    "    - [x] Test EDF file can be opened externally (e.g. through EDF.jl or other app)\n",
    "    - [x] Test EDF encodes max/min values\n",
    "    - [x] Get recording metadata\n",
    "- [ ] Turn prototype into library code\n",
    "- [ ] Add metadata to EDF header\n",
    "- [ ] Add tests\n",
    "- [ ] Write up edge case tests\n",
    "    - [ ] Make 'em pass OR file 'em\n",
    "- [ ] Clean up this notebook (delete this punch list!)\n",
    "- [ ] Mark PR ready for review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: this is the end goal\n",
    "\n",
    "```python\n",
    "# Example of usage once complete\n",
    "\n",
    "from DiveDB.services.duck_pond import DuckPond\n",
    "\n",
    "duckpond = DuckPond(os.environ[\"CONTAINER_DELTA_LAKE_PATH\"])\n",
    "\n",
    "dive_data = duckpond.get_delta_data(    \n",
    "    labels=[\"eeg\"],\n",
    "    animal_ids=\"apfo-001a\",\n",
    ")\n",
    "\n",
    "dive_data.export_to_edf(\"path_to_output.edf\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get metadata\n",
    "import os\n",
    "import importlib\n",
    "import DiveDB.services.duck_pond as dp\n",
    "importlib.reload(dp)\n",
    "\n",
    "duckpond = dp.DuckPond(os.environ[\"CONTAINER_DELTA_LAKE_PATH\"])\n",
    "\n",
    "# Example from the querying_docs notebook\n",
    "data = duckpond.get_delta_data(    \n",
    "    labels=[\"derived_data_depth\"],\n",
    "    animal_ids=\"apfo-001a\",\n",
    "    frequency=1/60,  # Once a minute\n",
    ")\n",
    "display(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Okay, but is there a way to find out what animal_ids, etc, are available?\n",
    "# Time to go spelunking!\n",
    "duckpond.get_db_schema()\n",
    "\n",
    "# ...okay, cool. :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a sql query as well (also ripped from the querying_docs notebook)\n",
    "labels_df = duckpond.conn.sql(f\"\"\"\n",
    "    SELECT label\n",
    "    FROM (\n",
    "        SELECT DISTINCT label\n",
    "        FROM DataLake\n",
    "    )\n",
    "\"\"\").df()\n",
    "# display(labels_df)\n",
    "\n",
    "animals_df = duckpond.conn.sql(f\"\"\"\n",
    "    SELECT animal\n",
    "    FROM (\n",
    "        SELECT DISTINCT animal\n",
    "        FROM DataLake\n",
    "    )\n",
    "\"\"\").df()\n",
    "# display(animals_df)\n",
    "\n",
    "signal_df = duckpond.conn.sql(f\"\"\"\n",
    "    SELECT class, label\n",
    "    FROM (\n",
    "        SELECT DISTINCT label, class\n",
    "        FROM DataLake\n",
    "    )\n",
    "\"\"\").df()\n",
    "display(signal_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_df.sort_values(by=\"class\")\n",
    "print(signal_df['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commenting out b/c otherwise this crashes my kernel (if i do other stuff after it)\n",
    "\n",
    "# # Once more from the other notebook....\n",
    "# # Get the filtered data\n",
    "# resampled_data = duckpond.get_delta_data(    \n",
    "#     animal_ids=\"apfo-001a\",\n",
    "#     # Resample values to 100 Hz and make sure each signal has the same time intervals\n",
    "#     frequency=100,\n",
    "#     # Aggregation of events (think state events - behaviors) type: state (has state and end dates)\n",
    "#     classes=\"sensor_data_accelerometer\",\n",
    "# )\n",
    "# display(resampled_data)\n",
    "# # Huh. okay, `frequency` triggering a materialization + resample is interesting, not sure \n",
    "# # I would have guessed that from the API! I would have guessed that had to do with \n",
    "# # the sampling rate of the recording.\n",
    "\n",
    "# # Okay, so the output of `get_delta_data` with a set frequency returns the signal as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Is there a way to get the original sample rate? \n",
    "unmaterialized_data = duckpond.get_delta_data(    \n",
    "    animal_ids=\"apfo-001a\",\n",
    "    # Resample values to 10 Hz and make sure each signal has the same time intervals\n",
    "    frequency=None,\n",
    "    # Aggregation of events (think state events - behaviors) type: state (has state and end dates)\n",
    "    classes=\"sensor_data_accelerometer\",\n",
    ")\n",
    "display(unmaterialized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... okay, got it. now, let's do what needs doing. \n",
    "# But also, keep in mind that we should NOT pass a frequency into `get_delta_data`\n",
    "# before EDF export unless we are very explicit about what we are doing and why. \n",
    "\n",
    "# When we don't pass in a frequency (i.e., resample), we get a DuckDBPyRelation\n",
    "# out of `get_delta_data`\n",
    "print(type(unmaterialized_data))\n",
    "\n",
    "# ...from task, I think we want a DuckDBPyConnection instead? Currently unclear to me\n",
    "# how these interop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, now to an EDF! \n",
    "# Let's do the demo from edfio (what mne depends on for its EDF support)\n",
    "\n",
    "from edfio import Edf, EdfSignal, read_edf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# edfio's example\n",
    "example_edf = Edf(\n",
    "    [\n",
    "        EdfSignal(np.random.randn(30 * 256), sampling_frequency=256, label=\"EEG Fpz\"),\n",
    "        EdfSignal(np.random.randn(30), sampling_frequency=1, label=\"Body Temp\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "outpath = \".tmp/example.edf\"\n",
    "example_edf.write(outpath)\n",
    "\n",
    "example_edf_roundtrip = read_edf(outpath)\n",
    "display(example_edf_roundtrip.signals)\n",
    "display(example_edf_roundtrip.signals[0].data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...and now with our data!\n",
    "# Can we make an EDF from our data? \n",
    "# intentionally picking signals with different sampling rates\n",
    "classes = [\"sensor_data_accelerometer\",\"sensor_data_pressure\", \"derived_data_prh\"]\n",
    "\n",
    "# Set up for EDF - first figure out what common max duration is, etc\n",
    "max_duration_sec = 0\n",
    "for class_name in classes:\n",
    "    df = duckpond.get_delta_data(animal_ids=\"apfo-001a\",\n",
    "                                 classes=[class_name],\n",
    "                                 ).df()\n",
    "\n",
    "    #TODO-optimize: surely there is a way to get the number of samples without loading them all?? \n",
    "    # If so, do that!\n",
    "    sampling_rate = df[\"datetime\"].diff()[1:].dt.total_seconds().unique()[0]\n",
    "    sampling_frequency = int(1/sampling_rate) # TODO-safety: don't just blindly round o_O\n",
    "\n",
    "    # TODO-correctly! need to figure out max signal length, then start time, then \n",
    "    # Lpad to the correct start time + lpad to the correct stop time (lol EDF)\n",
    "    # For now, we're faking it. We happen to know that the maximum duration signal \n",
    "    # of these two is 20 s, so lets zero-pad to that:\n",
    "    sig_max_duration_sec = math.ceil(df.shape[0] / sampling_frequency)\n",
    "    max_duration_sec = max(max_duration_sec, sig_max_duration_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now actually use the real data to create an edf\n",
    "signals = []\n",
    "for class_name in classes:\n",
    "    df = duckpond.get_delta_data(    \n",
    "        animal_ids=\"apfo-001a\",\n",
    "        classes=[class_name],\n",
    "    ).df()\n",
    "    df = df.drop(['recording', 'class'], axis=1)\n",
    "\n",
    "    # TODO-safety: check that there's only one value after the unique, check that \n",
    "    # this is an integer value or whatever the EDF spec requires, etc\n",
    "    sampling_rate = df[\"datetime\"].diff()[1:].dt.total_seconds().unique()[0]\n",
    "    sampling_frequency = int(1/sampling_rate) # TODO-safety: don't just blindly round, see if we allow floating point values here also?? o_O\n",
    "\n",
    "    if class_name.startswith(\"sensor_data\"):\n",
    "        class_prefix = class_name[12:]\n",
    "    elif class_name.startswith(\"derived_data\"):\n",
    "        class_prefix = \"**\" + class_name[13:]\n",
    "    else:\n",
    "        class_prefix = class_name\n",
    "\n",
    "    # Need to figure out max signal length, then start time, then \n",
    "    # Lpad to the correct start time + lpad to the correct stop time (lol EDF)\n",
    "    # TODO-future: instead of padding w/ 0, use some signal-specific value\n",
    "    num_channels = df.shape[1] - 1\n",
    "    i_sample_start_offset = 0 #TODO - make sure this is set to the signal's offset\n",
    "    for i_channel in range(0, num_channels):\n",
    "        signal_data = np.zeros(max_duration_sec * sampling_frequency, dtype=np.float64)\n",
    "        channel_label = (df.columns)[i_channel + 1]\n",
    "\n",
    "        # TODO-future safety: make sure signal labels are unique across recording\n",
    "        # TODO-future: pull into own function\n",
    "        if class_name == channel_label:\n",
    "            signal_label = class_prefix if len(class_prefix) <= 16 else class_prefix[0:16]  # lol EDF\n",
    "        else:\n",
    "            max_prefix_length = 16 - len(channel_label) - 1  # lol EDF \n",
    "            # TODO handle case when prefix is now < 0\n",
    "            signal_prefix = class_prefix if len(class_prefix) <= max_prefix_length else class_prefix[0:max_prefix_length]\n",
    "            signal_label = signal_prefix + \"-\" + channel_label\n",
    "\n",
    "        num_samples = len(df[channel_label].values)\n",
    "        signal_data[i_sample_start_offset:num_samples] = df[channel_label].values\n",
    "\n",
    "        signal = EdfSignal(signal_data,\n",
    "                           sampling_frequency=sampling_frequency, \n",
    "                           physical_dimension=\"TODO\",\n",
    "                           label=signal_label)\n",
    "        # TODO-add header metadata\n",
    "        signals.append(signal)\n",
    "    \n",
    "divedb_edf = Edf(signals)\n",
    "path = \".tmp/prototype.edf\"\n",
    "divedb_edf.write(path)\n",
    "\n",
    "divedb_edf_roundtrip = read_edf(path)\n",
    "display(divedb_edf_roundtrip.signals)\n",
    "display(divedb_edf_roundtrip.signals[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"sensor_data_accelerometer\"\n",
    "df = duckpond.get_delta_data(    \n",
    "    animal_ids=\"apfo-001a\",\n",
    "    classes=[class_name],\n",
    "    # limit=1000,\n",
    ").df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commenting out to avoid an unnecessary error! Uncomment to see the (fully expected) error. :) \n",
    "# # Can an edf contain nan or inf? \n",
    "\n",
    "# sig = np.random.randn(30 * 256)\n",
    "# sig[0] = np.nan\n",
    "# print(sig)\n",
    "# example_edf = Edf([EdfSignal(sig, sampling_frequency=256, label=\"EEG Fpz\")])\n",
    "\n",
    "# # nope! that answers that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sig in divedb_edf_roundtrip.signals:\n",
    "    print(sig)\n",
    "    print(sig.__dict__)\n",
    "\n",
    "sig = divedb_edf_roundtrip.signals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's practice setting the other fields for the recording \n",
    "from edfio import Patient, Recording\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "edf = divedb_edf_roundtrip.copy()\n",
    "\n",
    "# Okay, looks like these additional fields are VERY strict, disallow spaces, basically can't \n",
    "# be json. According to PA, canonical thing to do here is use annotations, so we'll do that \n",
    "# for anything interesting. Single world fields/responses? allowed, in the kwarg form \n",
    "additional = ('kwarg1', 'value1', 'kwarg2', 'value2')\n",
    "\n",
    "edf.recording = Recording(\n",
    "    # startdate=datetime.date(2002, 2, 2), #TODO\n",
    "    equipment_code=\"X\", #TODO\n",
    ")\n",
    "\n",
    "path = \".tmp/prototype.edf\"\n",
    "edf.write(path)\n",
    "edf.__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divedb_edf.recording.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huzzah! Time to clean up :) \n",
    "# ...actually false. Time to figure out how to get the metadata into the EDF header!\n",
    "# Check the edfio API: https://github.com/the-siesta-group/edfio?tab=readme-ov-file#usage \n",
    "# and https://edfio.readthedocs.io/en/stable/examples.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, how does this work now?\n",
    "import importlib, os\n",
    "import DiveDB.services.duck_pond as dp\n",
    "importlib.reload(dp)\n",
    "import DiveDB.services.dive_data as dd\n",
    "importlib.reload(dd)\n",
    "\n",
    "duckpond = dp.DuckPond(os.environ[\"CONTAINER_DELTA_LAKE_PATH\"])\n",
    "\n",
    "results = duckpond.get_delta_data(    \n",
    "    classes=[\"derived_data_depth\", \"sensor_data_accelerometer\"],\n",
    "    animal_ids=\"apfo-001a\",\n",
    "    limit=100, # 0000\n",
    ")\n",
    "print(type(results))\n",
    "# print(results.df())\n",
    "dd.export_to_edf(results, \"foo.edf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings = results.unique('recording').df()['recording'].values\n",
    "r = recordings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = duckpond.conn.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM Metadata.public.Recordings\n",
    "    WHERE Recordings.id = '2019-11-08_apfo-001a_apfo-001a_CC-35'\n",
    "\"\"\").df()\n",
    "display(metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DiveDB.services.dive_data as dd\n",
    "importlib.reload(dd)\n",
    "import DiveDB.services.duck_pond as dp\n",
    "importlib.reload(dp)\n",
    "\n",
    "duckpond = dp.DuckPond(os.environ[\"CONTAINER_DELTA_LAKE_PATH\"])\n",
    "\n",
    "results = duckpond.get_delta_data(    \n",
    "    classes=[\"derived_data_depth\", \"sensor_data_accelerometer\"],\n",
    "    animal_ids=\"apfo-001a\",\n",
    "    # limit=10, # 0000\n",
    ")\n",
    "results.get_metadata()\n",
    "results.duckdb_relation.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DiveDB.services.dive_data as dd\n",
    "importlib.reload(dd)\n",
    "\n",
    "metadata = results.metadata\n",
    "df = results.duckdb_relation.df()\n",
    "# metadata\n",
    "\n",
    "edf = None\n",
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.export_to_edf(\"temp.edf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
